{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 22 14:08:31 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.03   Driver Version: 450.119.03   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8    16W / 250W |     26MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8     1W / 250W |  10450MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1000      G   /usr/lib/xorg/Xorg                  9MiB |\n",
      "|    0   N/A  N/A      1140      G   /usr/bin/gnome-shell               14MiB |\n",
      "|    1   N/A  N/A      1000      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      6328      C   .../textmining/bin/python3.7    10441MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the pretrained_word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load w2v model\n",
    "w2v_model_cb = Word2Vec.load(\"/home/MOFdictionary/libs/word2vec/word2vec_cbow/word2vec_cbow.model\")\n",
    "w2v_model_sg = Word2Vec.load(\"/home/MOFdictionary/libs/word2vec/word2vec_skipgram/word2vec_skipgram.model\")\n",
    "\n",
    "ft_model_cb = Word2Vec.load(\"/home/MOFdictionary/libs/word2vec/fasttext_cbow/fasttext_cbow.model\")\n",
    "ft_model_sg = Word2Vec.load(\"/home/MOFdictionary/libs/word2vec/fasttext_skipgram/fasttext_skipgram.model\")\n",
    "\n",
    "wv_model = w2v_model_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105075"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([105077, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_embedding = 100\n",
    "embedding_matrix = tf.concat([tf.zeros((2, dim_embedding)), wv_model.wv.vectors], axis=0)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105077"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"<PAD>\",\"<UNK>\"] + wv_model.wv.index2word\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {}\n",
    "for i, word in enumerate(words):\n",
    "    word2id[word] = i\n",
    "    \n",
    "id2word = {}\n",
    "for i, word in enumerate(words):\n",
    "    id2word[i] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(word2id, open(\"/home/MOFdictionary/libs/mer/vocab/word2id\",\"wb\"))\n",
    "#pickle.dump(id2word, open(\"/home/MOFdictionary/libs/mer/vocab/id2word\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bio_tags(tags):\n",
    "    \n",
    "    bio_tags = []\n",
    "    \n",
    "    for i, tag in enumerate(tags):\n",
    "        if i == 0: # B-\n",
    "            \n",
    "            if tag == 1: #pre\n",
    "                bio_tag = 3 #B-pre\n",
    "                \n",
    "            elif tag == 2: #etc\n",
    "                bio_tag = 5 #B-Etc\n",
    "                \n",
    "            elif tag == 3: #tar\n",
    "                bio_tag = 1 #B-tar\n",
    "                \n",
    "            else:\n",
    "                bio_tag = 0\n",
    "        \n",
    "        else:\n",
    "            if tag == 1: #pre\n",
    "                if tags[i-1] == 1:\n",
    "                    bio_tag = 4 #I-pre\n",
    "                else:\n",
    "                    bio_tag = 3 #B-pre\n",
    "                    \n",
    "            elif tag == 2: #etc\n",
    "                if tags[i-1] == 2:\n",
    "                    bio_tag = 6 #I-etc\n",
    "                else:\n",
    "                    bio_tag = 5 #B-etc\n",
    "                    \n",
    "            elif tag == 3: #tar\n",
    "                if tags[i-1] == 3:\n",
    "                    bio_tag = 2 # I-tar\n",
    "                else:\n",
    "                    bio_tag = 1 # B-atr\n",
    "                    \n",
    "            else:\n",
    "                bio_tag = 0\n",
    "        \n",
    "        bio_tags.append(bio_tag)\n",
    "    \n",
    "    return bio_tags         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "map_sents = []\n",
    "bio_tags = []\n",
    "for filepath in Path(\"/home/MOFdictionary/example/Dataset_MER/\").glob(\"*.sav\"):\n",
    "    ners = pickle.load(open(filepath,\"rb\"))\n",
    "    for ner in ners: #ners = [[(word,tag),(word,tag),,,],[],,,]\n",
    "        words, tags = zip(*ner)\n",
    "        sents.append(words)\n",
    "        map_sents.append(list(map(lambda x: word2id[x] if x in word2id else 1, words)))\n",
    "        bio_tags.append(get_bio_tags(tags)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11173, 100) (11173, 100)\n"
     ]
    }
   ],
   "source": [
    "max_length = 100\n",
    "num_tags = 7\n",
    "\n",
    "x_data = pad_sequences(map_sents, maxlen=max_length, padding=\"post\")\n",
    "y_data = pad_sequences(bio_tags, maxlen=max_length, padding=\"post\")\n",
    "#y_data = to_categorical(y_data, num_classes=num_tags) # make one-hot sequence\n",
    "\n",
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8938, 100) (1117, 100) (8938, 100) (1117, 100)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test_val, y_train, y_test_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test_val, y_test_val, test_size=0.5, random_state=42)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. character Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of charlist = 101\n"
     ]
    }
   ],
   "source": [
    "## making charlist\n",
    "charlist = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 ~†‡°·-,;.!?:’/\\|_@#$%ˆ&*˜‘+-=()[]{}<>\"\n",
    "\n",
    "# char2idx\n",
    "char2id = {}\n",
    "\n",
    "char2id[\"PAD\"] = 0\n",
    "char2id[\"UNK\"] = 1\n",
    "for i, char in enumerate(charlist):\n",
    "    char2id[char] = i+2\n",
    "print(f\"# of charlist = {len(char2id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(char2id, open(\"/home/MOFdictionary/libs/mer/vocab/char2id\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_map_char_sequences(x_data):\n",
    "    x_data_char  = np.empty([x_data.shape[0], x_data.shape[1], 30])\n",
    "    for i, sent in enumerate(x_data):\n",
    "\n",
    "        map_sent = []\n",
    "\n",
    "        for word in sent:\n",
    "\n",
    "            map_word = list(map(lambda x : char2id[x] if x in char2id else 1, id2word[word]))\n",
    "            if map_word == [100,43, 28, 31,101]: #<PAD> -> 0\n",
    "                map_word = [0]\n",
    "            map_sent.append(map_word)\n",
    "\n",
    "        x_data_char[i] = pad_sequences(map_sent,padding=\"post\",maxlen=30)\n",
    "    x_data_char.shape\n",
    "    return x_data_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8938, 100, 30), (1117, 100, 30), (1118, 100, 30))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_char = get_pad_map_char_sequences(x_train)\n",
    "x_test_char = get_pad_map_char_sequences(x_test)\n",
    "x_val_char = get_pad_map_char_sequences(x_val)\n",
    "x_train_char.shape, x_test_char.shape, x_val_char.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf2crf import CRF, ModelWithCRFLoss\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, RNN, LSTMCell, TimeDistributed, Concatenate, Dense\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_scores(y_true, y_pred, lens_text):\n",
    "    mask = tf.sequence_mask(lens_text, maxlen=100)\n",
    "    m = tf.keras.metrics.Accuracy()\n",
    "    acc = m(y_true, y_pred, sample_weight=mask)\n",
    "    # precision, recall, f1 for multi-class\n",
    "    \n",
    "    masked_y_true = y_true[mask]\n",
    "    masked_y_pred = y_pred[mask]\n",
    "    accuracy = accuracy_score(masked_y_true, masked_y_pred)\n",
    "    precision = precision_score(masked_y_true, masked_y_pred, average=None)\n",
    "    recall = recall_score(masked_y_true, masked_y_pred, average=None)\n",
    "    f1 = f1_score(masked_y_true, masked_y_pred, average=None)\n",
    "    return acc.numpy(), precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONLL scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = tf.keras.models.load_model(\"./keras/bilstmcrf_char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99343276,\n",
       " array([0.99736943, 0.89156627, 0.81818182, 0.94252874, 0.91428571,\n",
       "        0.91286307, 0.85333333]),\n",
       " array([0.99690416, 0.92789969, 0.9       , 0.93447293, 0.92753623,\n",
       "        0.90163934, 0.85333333]),\n",
       " array([0.99713674, 0.9093702 , 0.85714286, 0.93848355, 0.92086331,\n",
       "        0.90721649, 0.85333333]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, _, lens_text, _ = load_model((x_test, x_test_char))\n",
    "mask_scores(y_test, y_pred, lens_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conll_score(masked_y_true, masked_y_pred, labels):\n",
    "    \n",
    "    # true\n",
    "    cond = tf.logical_or(masked_y_true==labels[0], masked_y_true==labels[1])\n",
    "    l = tf.where(cond, 1, 0)\n",
    "    idx_list_true = np.where(l == 1)[0] \n",
    "    \n",
    "    list_true = []\n",
    "    remove_idx = []\n",
    "    for i, idx in enumerate(idx_list_true):\n",
    "\n",
    "        t = (idx, 0)\n",
    "        \n",
    "        if i <= len(idx_list_true) -2 and idx_list_true[i+1] - idx_list_true[i] == 1:\n",
    "            t = (idx, 1)\n",
    "            remove_idx.append(i+1)\n",
    "\n",
    "            if i <= len(idx_list_true) -3 and idx_list_true[i+2] - idx_list_true[i] == 2:\n",
    "                t = (idx, 2)\n",
    "                remove_idx.append(i+2)\n",
    "                \n",
    "                if i <= len(idx_list_true) -4 and idx_list_true[i+2] - idx_list_true[i] == 3:\n",
    "                    t = (idx, 3)\n",
    "                    remove_idx.append(i+3)\n",
    "\n",
    "\n",
    "        list_true.append(t)    \n",
    "    final_true = np.delete(np.array(list_true), list(set(remove_idx)), axis=0)\n",
    "    \n",
    "    # pred\n",
    "    cond = tf.logical_or(masked_y_pred==labels[0], masked_y_pred==labels[1])\n",
    "    l = tf.where(cond, 1, 0)\n",
    "    idx_list_pred = np.where(l == 1)[0]\n",
    "    \n",
    "    list_pred = []\n",
    "    remove_idx = []\n",
    "    for i, idx in enumerate(idx_list_pred):\n",
    "\n",
    "        t = (idx, 0)\n",
    "\n",
    "        if i <= len(idx_list_pred) -2 and idx_list_pred[i+1] - idx_list_pred[i] == 1:\n",
    "            t = (idx, 1)\n",
    "            remove_idx.append(i+1)\n",
    "\n",
    "            if i <= len(idx_list_pred) -3 and idx_list_pred[i+2] - idx_list_pred[i] == 2:\n",
    "                t = (idx, 2)\n",
    "                remove_idx.append(i+2)\n",
    "                \n",
    "                if i <= len(idx_list_pred) -4 and idx_list_pred[i+2] - idx_list_pred[i] == 3:\n",
    "                    t = (idx, 3)\n",
    "                    remove_idx.append(i+3)\n",
    "\n",
    "        list_pred.append(t)    \n",
    "    final_pred = np.delete(np.array(list_pred), list(set(remove_idx)), axis=0)\n",
    "    \n",
    "    # precision\n",
    "    ans = 0\n",
    "    for pred in final_pred:\n",
    "        for true in final_true:\n",
    "            if all(true == pred):\n",
    "                ans += 1\n",
    "    precision = ans/len(final_pred)\n",
    "    # recall\n",
    "    ans = 0\n",
    "    for true in final_true:\n",
    "        for pred in final_pred:\n",
    "            if all(true == pred):\n",
    "                ans += 1\n",
    "    recall = ans / len(final_true)\n",
    "    \n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8905775075987842, 0.9272151898734177, 0.9085271317829458)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll_score(masked_y_true, masked_y_pred, labels=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9337175792507204, 0.9230769230769231, 0.9283667621776505)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll_score(masked_y_true, masked_y_pred, labels=[3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9053497942386831, 0.9016393442622951, 0.9034907597535935)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll_score(masked_y_true, masked_y_pred, labels=[5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
